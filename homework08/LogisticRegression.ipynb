{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логическая регрессия\n",
    "Рассмотрим логистическую регрессию на примере набора данных цветов ириса.\n",
    "Для простоты будем использовать только два признака Sepal Width и Sepal Length, а также два класса Setosa и Versicolor. Итак, наша задача построить разделяющую границу (decision boundary), которая бы позволила нам отделить наблюдения одного класса (Setosa) от другого (Versicolor). Мы хотим построить модель, которая позволит нам прогнозировать бинарный отклик, а точнее вероятность отнесения наблюдения к одному из классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, alpha=0.01, max_iter=1000):\n",
    "        self.alpha = alpha\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        X_train = X_train.tolist()\n",
    "        y_train = y_train.tolist()\n",
    "        \n",
    "        X_matrix = []\n",
    "        for i in range(len(X_train)):\n",
    "            X_train[i].insert(0, 1)\n",
    "            X_matrix.append(X_train[i])\n",
    "        X_as_matrix = np.asmatrix(X_matrix)\n",
    "        \n",
    "        y_matrix = []\n",
    "        for i in range(len(y_train)):\n",
    "            y_matrix.append([y_train[i]])\n",
    "            \n",
    "        m = len(y_train)\n",
    "        self.theta = np.zeros((len(X_matrix[0]), 1))\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            self.theta -= self.alpha * (1 / m) * (np.matmul(X_as_matrix.T,(np.matmul(X_matrix, self.theta) - y_matrix)))\n",
    "\n",
    "        theta_all = np.matrix.tolist(self.theta)\n",
    "        self.coef_ = theta_all[1:]\n",
    "        self.intercept_ = theta_all[0]\n",
    "        return theta_all\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        X_test = X_test.tolist()\n",
    "        X_matrix_test = []\n",
    "        for i in range(len(X_test)):\n",
    "            X_test[i].insert(0, 1)\n",
    "            X_matrix_test.append(X_test[i])\n",
    "        z = np.matmul(X_matrix_test, self.theta)\n",
    "        answers = 1/(1 + math.e **(-z))\n",
    "        return answers\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        \n",
    "        X_test = X_test.tolist()\n",
    "        X_matrix_test = []\n",
    "        for i in range(len(X_test)):\n",
    "            X_test[i].insert(0, 1)\n",
    "            X_matrix_test.append(X_test[i])\n",
    "        z = np.matmul(X_matrix_test, self.theta)\n",
    "        answers = np.round(1/(1 + math.e **(-z)))\n",
    "        return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.73387368]\n",
      " [0.51854271]\n",
      " [0.5178275 ]\n",
      " [0.76087074]\n",
      " [0.46815018]\n",
      " [0.52104188]\n",
      " [0.52889292]\n",
      " [0.5703133 ]\n",
      " [0.48385427]\n",
      " [0.70262178]\n",
      " [0.52960663]\n",
      " [0.66426802]\n",
      " [0.78423862]\n",
      " [0.5811485 ]\n",
      " [0.74134998]\n",
      " [0.50280953]\n",
      " [0.79725872]\n",
      " [0.71560832]\n",
      " [0.48850225]\n",
      " [0.69387922]\n",
      " [0.55870415]\n",
      " [0.69721268]\n",
      " [0.72397716]\n",
      " [0.57661273]\n",
      " [0.5178275 ]\n",
      " [0.55552691]\n",
      " [0.72197186]\n",
      " [0.5020934 ]\n",
      " [0.76034915]\n",
      " [0.73022404]\n",
      " [0.5703133 ]\n",
      " [0.49172024]\n",
      " [0.72197186]]\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "df = datasets.load_iris()\n",
    "X = df.data[:100, :2]\n",
    "y = df.target[:100]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=18)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "result = model.fit(X_train, y_train)\n",
    "answers = model.predict(X_test)\n",
    "print(answers)\n",
    "answers = model.predict_proba(X_test)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0.4436033825235975], [-0.601019905805465]], [-0.04310699544373814])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_, model.intercept_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
